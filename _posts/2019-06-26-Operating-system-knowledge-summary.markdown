---
layout: post
title: Operating-system-knowledge-summary
date: 2019-06-26 11:25:40 +0800
description: This blog covers the basics of operating system, memory management, process management, file operations and more.
img:  # Add image post (optional)
tags: [Operating System]
---



![操作系统知识点]({{site.baseurl}}/assets/img/操作系统知识点.png)

## 一、操作系统的基础

> 参考网址：https://blog.csdn.net/fancefu/article/details/79357048

#### 1、操作系统内核特征

- 并发：**在一段时间内，有多个程序可以运行**（并行：在一个时间点上有多个程序可以执行）
- 共享：**同一个资源多个进程同时访问**；1、同时共享；2、互斥共享。互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，否则会出现错误，需要用同步机制来实现对临界资源的访问。
- 虚拟：CPU-进程；磁盘-文件；内存-地址空间；**通过虚拟内存技术将一个物理实体虚拟成多个逻辑实体**，让用户以为自己独占一份内存空间。主要有两种虚拟技术：时分复用技术和空分复用技术，例如多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换，这样就好像有多个处理器进行处理。
- 异步：操作系统给不同线程分配CPU时间段，使得程序“走走停停”。

#### 2、操作系统的三大组件

- CPU、内存、磁盘

#### 3、操作系统的主要功能

- 处理机管理：处理机分配都是以进程为单位，所以处理机管理也被看做是进程管理。包括进程控制，进程同步，进程通信和调度(作业调度和进程调度)
- 存储器管理（或者内存管理）：内存分配，内存保护，地址映射，内存扩充
- 设备管理：管理所有外围设备，包括完成用户的IO请求；为用户进程分配IO设备；提高IO设备利用率；提高IO速度；方便IO的使用
- 文件管理：管理用户文件和系统文件，方便使用同时保证安全性。包括：文件存储空间管理，目录管理，文件读写管理以及文件共享和保护
- 提供用户接口：程序接口（如API）和用户接口（如GUI）

#### 4、系统调用

**如果一个进程在用户态需要用到操作系统的一些功能，就需要使用系统调用从而*陷入*内核，由操作系统代为完成。**可以由系统调用请求的功能有设备管理、文件管理、进程管理、进程通信、存储器管理等。

#### 5、中断

- **外中断**：由 CPU 执行指令以外的事件引起，如 I/O 结束中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
- **异常**：由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。
- **陷入**：在用户程序中使用系统调用。

#### 6、大内核和微内核

1. 大内核：大内核是将操作系统功能作为一个紧密结合的整体放到内核，由于各模块共享信息，因此有很高的性能。
2. 微内核：由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。但是需要频繁地在用户态和核心态之间进行切换，会有一定的性能损失。



***



## 二、操作系统的内存管理

> 分连续内存分配参考链接：https://www.jianshu.com/p/d254b138de03
>
> 页面置换算法参考链接：https://blog.csdn.net/snowbaby1234/article/details/81127584 
>
> 其他参考链接：https://www.cnblogs.com/inception6-lxc/p/9073983.html

#### 1、逻辑地址&物理地址&虚拟内存

- 物理地址：与物理内存直接对应（内存条与硬盘中的内存）
- **逻辑地址：是指计算机用户(例如程序开发者)，看到的地址。**例如，当创建一个长度为100的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为4个字节，故第二个元素的地址时起始地址加4，以此类推。事实上，**逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址(在内存条中所处的位置)，并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维**。
- 虚拟内存：操作系统读写内存的速度可以比读写磁盘的速度快几个量级。但是，内存价格也相对较高，不能大规模扩展。于是，**操作系统可以通过将部分不太常用的数据移出内存，“存放到价格相对较低的磁盘缓存，以实现内存扩展**。操作系统还可以通过算法预测哪部分存储到磁盘缓存的数据需要进行读写，提前把这部分数据读回内存。**虚拟内存空间相对磁盘而言要小很多，因此，即使搜索虚拟内存空间也比直接搜索磁盘要快。唯一慢于磁盘的可能是，内存、虚拟内存中都没有所需要的数据，最终还需要从硬盘中直接读取。**这就是为什么内存和虚拟内存中需要存储会被重复读写的数据，否则就失去了缓存的意义。现代计算机中有一个专门的**转译缓冲区(Translation Lookaside Buffer，TLB)**，用来实现虚拟地址到物理地址的快速转换。

#### 2、Windows下三种内存管理方法

- 虚拟内存，最适合用来管理大型对象或者结构数组；
- 内存映射文件，最适合用来管理大型数据流（通常来自文件）以及在单个计算机上运行多个进程之间共享数据；
- 内存堆栈，最适合用来管理大量的小对象。

#### 3、内碎片和外碎片

- 在内存管理中，**内部碎片是已经被分配出去的的内存空间大于请求所需的内存空间**。**外部碎片是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块**。
- 固定分区存在内部碎片，可变式分区分配会存在外部碎片；
- **页式虚拟存储**系统存在**内部碎片**：为了有效的利用内存，使内存产生更少的碎片，要对内存分页，内存以页为单位来使用，最后一页往往装不满，于是形成了内部碎片。
- **段式虚拟存储**系统存在**外部碎片**：为了共享要分段，在段的换入换出时形成外部碎片，比如5K的段换出后，有一个4k的段进来放到原来5k的地方，于是形成1k的外部碎片。

#### 4、连续内存分配法

- **首次**适配：要分配一块内存，从0地址开始寻找空闲内存，找到第一个适合待分配内存的空闲内存就分配给他
- **最优**适配：要分配一块内存，首先寻找内存中全部的空闲内存块，建立一个内存递增链，然后找出最匹配的那个
- **最差**适配：与最优分配正好相反，建立递减连，寻找相差最大的那个

#### 5、碎片内存管理法

> 无论哪种连续内存分配算法，都会产生更小的内存碎片，因此需要碎片内存管理来进一步优化系统内存

- 压缩式内存整理：将成片内存进行移动，使得碎片内存压缩到一起。移动内存开销大
- 交换式内存整理：运行程序需要更多的内存，将等待的程序的内存先放入硬盘上，腾出空闲的内存块交给正在运行的内存。**换入换出的内存粒度是以程序为单元的**

#### 6、非连续内存分配：分段

> 目标：连续内存分配会产生**内碎片**和**外碎片**，因此想用非连续内存分配算法（分段和分页）改善内碎片和外碎片的情况

分段内存管理当中，**地址是二维的，一维是段号，一维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的**。由于分段管理中，**每个段内部是连续内存分配**，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。段表中的每一个表项记录了该段在内存中的起始地址和该段的长度。段表可以放在内存中也可以放在寄存器中。访问内存的时候根据段号和段表项的长度计算当前访问段在段表中的位置，然后访问段表，得到该段的物理地址，根据该物理地址以及段内偏移量就可以得到需要访问的内存。由于也是两次内存访问，所以分段管理中同样引入了联想寄存器。

段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

![分段内存分配示意图]({{site.baseurl}}/assets/img/分段内存分配示意图.png)

#### 7、非连续内存分配：分页

把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录逻辑地址和实际存储地址之间的映射关系，以实现从页号到物理块号的映射。**

由于页表也是存储在内存中的，因此和不适用分页管理的存储方式相比，访问分页系统中内存数据需要**两次的内存访问**(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。

![分页内存分配示意图]({{site.baseurl}}/assets/img/分页内存分配示意图.png)

为了减少两次访问内存导致的效率影响，分页管理中引入了快表机制，包含快表机制的内存管理中，当要访问内存数据的时候，首先将页号在快表中查询，如果查找到说明要访问的页表项在快表中，那么直接从快表中读取相应的物理块号；如果没有找到，那么访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中(可能存在快表换出算法)。

在某些计算机中如果内存的逻辑地址很大，将会导致程序的页表项会很多，而页表在内存中是连续存放的，所以相应的就需要较大的连续内存空间。为了解决这个问题，可以采用**两级页表或者多级页表的方法**，其中外层页表一次性调入内存且连续存放，内层页表离散存放。相应的访问内存页表的时候需要一次地址变换，访问逻辑地址对应的物理地址的时候也需要一次地址变换，而且一共需要访问内存3次才可以读取一次数据。

#### 8、分段和分页的比较

##### 1）、两者的优缺点

在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。**段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）**

在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。**页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）**

##### 2）、两者的不同点

1. 满足需求对象不同：分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。
2. 两者长度是否固定：**页的大小固定且由系统决定**，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；**而段的长度却不固定**，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
3. 分页作业的地址空间维度不同：**分页的作业地址空间是一维的**，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；**而分段的作业地址空间则是二维的**，程序员在标识一个地址时，既需给出段名，又需给出段内地址。
4. 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；

#### 9、内存的页面置换算法

地址映射过程中，如果页面中发现所要访问的页面不在内存中，则产生**缺页中断**，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

- 最佳置换算法（OPT）(理想置换算法)：从当前位置看后面的页面引用串，选择最长时间不需要被访问的页面来进行置换。最好是选择以后永远都不需要再使用的页面，这样可以保证最低的缺页率。（OPT算法可以用来评价其他算法）
- 先进先出置换算法（FIFO）：最简单的页面置换算法。基本思想是，**选择驻留内存时间最长的页面进行置换**，也就是先进先出。就相当于一个队列，当页面在队列里排满时，将队列头部的页面取出，置换成新的页面，但需要注意的是新的页面将置于队尾的位置。（FIFO算法会出现Belady异常：当所分配的物理块数增大时缺页次数不减反增的异常现象）
- 最近最久未使用算法（LRU）：基本思想是利用局部性原理，当一个**页面在最近的访问历史中最久未被使用**时，我们推测它未来使用的可能性也很小，因此将其进行置换。实现原理：将使用的页面放入一个链表，当再次访问某一页面时，将其放置尾部。置换时从头部开始置换，即置换最老的且未被重新访问过的页面。（ LRU 的性能最好，但是需要寄存器和硬件的支持。LRU 是堆栈类的算法，不会出现Belady现象。）
- 第二次机会算法：将被访问的页面装入一个链表，并设置一个R位，头部为最先进入链表的，当页面被访问时，将其R 位设置为1；在选择置换页面时，当头部的页面R值为0，则被置换；若为1，则将R设置为0，并分析链表下一个页面。新装入的页面，R为0，并放在链表尾部。（其实和LRU的原理一样，但增加了一个R位指标，所以不需要经常更换链表顺序）
- 时钟（ CLOCK ）置换算法： 使用环形链表将页面链接起来，并使用指针指向最老的页面。
- 最不常用算法（LFU）：当缺页中断发生时，选择**访问次数最少的那个页**，淘汰之

#### 10、抖动

抖动是指系统进行频繁的置换页的活动，使得内外储存频繁交换，从而引起系统效率降低的现象。决解方法：1、修改算法；2、降低进程数量；3、增加内存，增加程序运行过程中的页数量

发生抖动的原因：直接原因-页面置换算法不合适；根本原因-内存不足



#### 11、局部性原理

在程序设计时要考虑**时间局部性**（一条指令的这次执行和下次执行，一个数据的这次访问和下次访问）和**空间局部性**（指令执行和数据访问都集中在一小部分），有了局部性原理便能更好的应用虚拟内存技术

***



## 三、进程和线程

> 参考链接：
>
> https://blog.csdn.net/sunxianghuang/article/details/51883496
>
> https://blog.csdn.net/justloveyou_/article/details/78304294
>
> https://blog.csdn.net/daijie2198492527/article/details/62435380
>
> https://www.jianshu.com/p/d254b138de03
>
> https://www.cnblogs.com/inception6-lxc/p/9073983.html
>
> https://www.cnblogs.com/lustar/p/8087496.html

#### 1、核心态与用户态

计算机系统都有两种运行状态，即**核心态**和**用户态**，在某一时刻二者必居其一。当操作系统内核的程序模块运行时，机器处于核心态，其他程序（包括OS外壳程序和其他应用程序）运行时机器处于用户态。

- 用户态：用户态具有较低特权的执行状态，在这种状态下，处理机只能执行规定的指令，访问指定的寄存器和存储区，用户程序通常只能在这一级别执行。

- 核心态：核心态是操作系统内核的运行状态，在这种状态下，处理机具有较高的特权，能执行一切指令，可以访问所有的寄存器和存储区。

在实际系统中，之所以要区分机器的两种运行状态，目的是给操作系统内核以某些特权。例如，改变状态寄存器和地址映射寄存器的内容等。这些特权是通过执行特权指令实现的，仅当在核心态下才能执行特权指令。

![用户态与核心态]({{site.baseurl}}/assets/img/用户态与核心态.png)

**当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；**

反之，**当程序运行在级特权级上时，就可以称之为运行在内核态。**

虽然用户态下和内核态下工作的程序有很多差别，**但最重要的差别就在于特权级的不同，即权力的不同。**运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。

当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。

##### 1）、用户态切换到内核态的3种方式

1. 系统调用：这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。
2. 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
3. 外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

#### 2、进程的基本状态

- 运行状态：进程正在处理机上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。
- 就绪状态：进程已处于准备运行的状态，即进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行。
- 阻塞状态，又称等待状态：进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理机）或等待输入/输出完成。即使处理机空闲，该进程也不能运行。

![进程的三种状态]({{site.baseurl}}/assets/img/进程的三种状态.png)

#### 3、进程与线程定义

- 进程描述：
  - 一个具有一定独立功能的程序在一个数据集上的一次动态执行过程；
  - 进程是**系统进行资源分配和调度**的一个独立单位。
  - 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，**所谓的创建进程和撤销进程，都是指对 PCB 的操作**。
  - 进程由三部分组成：**进程控制块**（PCB）、**程序段**和**数据段**。在创建进程时，向系统申请一个空闲的PCB，并制定唯一的进程标识号PID。
  - **进程可以共享的资源**：进程间可以共享的数据有以下几类，进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。
- 线程描述：
  - 同属一个进程的其他的线程共享进程所拥有的全部资源（包括地址空间）。
  - 线程是**独立调度的基本单位**。
  - 线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)。因此，它的创建、撤销、切换所需要的时空开销比进程要小。
  - 线程的引入可进一步提高系统的并发性。

#### 4、进程与线程的区别

**进程和线程的主要差别在于它们是不同的操作系统资源管理方式。**进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。

- 调度分派：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。
- 资源拥有：进程是资源分配的基本单位，但是线程不拥有资源；进程是一个或多个线程和相关资源的集合。线程基本不拥有资源，它的运行资源取决于其所属的进程。
- 地址空间：**不同进程的地址空间是相互独立的，而同一个进程的各线程共享同一地址空间。**
- 一个进程可包含一个或多个线程，反过来则不然。一个进程中的线程在另一个进程中时不可见的。
- 通信关系：**进程间通信 (IPC) 需要进程同步和互斥手段的辅助**，以保证数据的一致性，而线程间可以通过直接读/写进程数据段（如全局变量）来进行通信。
- 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置。而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此，这些线程之间的同步与通信非常容易实现，甚至无需操作系统的干预。

#### 5、用户级线程和内核线程

线程的类型：对于通常的进程，不论是系统进程还是用户进程，在进行切换时都要依赖内核中的进程调度。因此，不论什么进程都是与内核有关的，而且是在内核支持下进行切换的。根据线程的控制方式不同，可将线程分为内核线程和用户级线程。

- **内核级线程：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。**无论是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。为此，需要在内核中建立一个线程控制块，内核根据该控制块而感知该线程的存在并对线程进行控制。
- **用户级线程：它仅存在于用户级中，这种线程是不依赖于操作系统核心的。**应用进程利用线程库来完成其创建、同步、调度和管理线程。因此用户线程间的切换不需要内核特权，不需要用户态/核心态切换，速度快，操作系统内核无法感知用户级线程的存在。

##### 1)、用户级线程和内核级线程的区别

1. 内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。
2. 用户级线程的创建、撤消和调度不需要OS内核的支持；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。
3. **用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。**
4. 在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。
5. **用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。**

##### 2）、内核线程的优点、缺点

- 优点：当有多个处理机时，一个进程的多个线程可以同时执行。
- 缺点：由内核进行调度

##### 3）、用户线程的优点、缺点

- 优点：
  1. 线程的调度不需要内核直接参与，控制简单。
  2. 可以在不支持线程的操作系统中实现。
  3. 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。
  4. 允许每个进程定制自己的调度算法，线程管理比较灵活。这就是必须自己写管理程序，与内核线程的区别。
  5. 线程能够利用的表空间和堆栈空间比内核级线程多。
  6. 同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。另外，页面失效也会产生同样的问题。

- 缺点：资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用

#### 6、关于fork和vfork

- fork产生子进程，子进程拥有父进程的副本，只共享正文段（其实现在的实现采用了写时复制`copy on write`的技术，先让子进程只读共享内存，如果有一个提出修改请求之后，才会产生变量的副本）和文件偏移量。
- fork的两个用法：
  - 一个进程创建一个自身的副本，让他们互相执行自己的任务。
  - 一个进程想要执行另外一个程序，fork之后调用exec进行新程序环境替换。会替换当前进程的正文段、数据段堆和栈；（此时的写时复制技术（COW）就可以避免了复制父进程的进程环境）
  - 在调用exec之后，打开的描述符默认会跨exec打开。（当然，可以设置禁止跨exec，也可以手动关闭）
- vfork创建子进程，**不完全复制地址空间**，保证子进程先运行，子进程调用exec或者exit之后父进程才能被调度。父子进程只是共享代码段，其他的变量都不会共享，只是复制，也就是说，**在子进程中修改一个变量，父进程中的该变量是不会改变的。**文件描述符（涉及到计数的问题）也是复制，相当于执行了dup，文件偏移量共享。

#### 7、PID参数对应信息

- pid == -1：等待任一子进程
- pid > 0：等待进程号等于pid的子进程
- pid == 0：等待与调用进程为同组的任一进程
- pid < -1：组ID等于pid绝对值的任一进程

#### 8、进程调度算法

> 详细描述链接：https://blog.csdn.net/luyafei_89430/article/details/12971171

- **先来先服务调度算法FCFS，First-Come-First-Served：**
  - 既可以作为作业调度算法也可以作为进程调度算法；
  - 按作业或者进程到达的先后顺序依次调度；因此对于长作业比较有利；因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。
- **短作业优先调度算法SJF（SPN，Shortest Process Next）：**
  - 作业调度算法
  - 算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行；
  - 缺点：不利于长作业，如果一直有短作业到来，那么长作业永远得不到调度。未考虑作业的重要性；运行时间是预估的，并不准确；
- **高相应比算法HRRN，Highest Response Ratio Next：**
  - 响应比=(响应时间+服务时间)/服务时间；
  - 综合考虑了响应时间与等待时间因素，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行。
- **时间片轮转调度算法（RR，Round-Robin）：**
  - 当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。
  - 时间片轮转算法的效率和时间片有很大关系。因为每次进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太短，进程切换太频繁，在进程切换上就会花过多时间。 
- **优先权(Priority)调度算法：**
  - 按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。
- **多级反馈队列调度算法：**
  - 目前公认较好的调度算法；
  - 设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。

#### 9、临界资源

- 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但**对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源**。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。
- **对于临界资源的访问，必须是互斥进行。**也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。**而进程内访问临界资源的代码被成为临界区。**

#### 10、进程的同步

进程同步的主要任务：是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。进程间同步的主要方法有**原子操作、信号量机制、自旋锁、管程、会合、分布式系统**等。

同步机制遵循的原则：

- 空闲让进
- 忙则等待（保证对临界区的互斥访问）
- 有限等待（有限代表有限的时间，避免死锁等）
- 让权等待（当进程不能进入自己的临界区时，应该释放处理机，以免陷入忙等状态）。

#### 11、线程的同步

- 临界区：通过对多线程的串行化来访问公共资源或者一段代码，速度快，适合控制数据访问

- 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

- 信号量 Semphare：

  - 它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
  - P操作：如果信号量大于 0 ，执行 - 1 操作；如果信号量等于 0，将进程睡眠，等待信号量大于 0；
  - V操作：对信号量执行 + 1 操作，并且唤醒睡眠的进程，让进程完成 down 操作。
  - P和V操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。
  - 生产者和消费者问题：

  ```c
  #define N 100
  typedef int samaphore;
  samaphore mutex = 1;
  samaphore empty = N;
  samaphore full = 0;
  
  void producer() {
      while(TRUE){
          int item = produce_item;
          down(empty);
          down(mutex);
          insert_item(item);
          up(mutex);
          up(full);
      }
  }
  
  void consumer() {
      while(TRUE){
          down(full);
          down(mutex);
          int item = remove_item(item);
          up(mutex);
          up(empty);
          consume_item(item);
      }
  }
  ```

  

- 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

- 管程机制：使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

- 自旋锁----多处理器：获取/释放自旋锁；单处理器：禁止/使用内核抢占

#### 12、pcb进程控制块
- 进程标志 进程状态 程序计数器 寄存器
- cpu调度信息：进程优先级、调度队列指针、其他调度参数
- 内存管理信息：基址寄存器 界限寄存器 页表/段表
- 记账信息：cpu时间、实际使用时间、时间界限、记账数据、作业或进程数量
- I/O状态信息：分配给进程的IO设备列表、打开文件列表

#### 13、进程通信

进程通信可以看成是不同进程间的线程通信，对于同一个进程内线程的通信方式，主要使用信号量、条件变量等同步机制。

##### 1）、管道

管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

Linux 中管道是通过空文件来实现。

管道有三种：

① 普通管道：有两个限制：一是只支持半双工通信方式，即只能单向传输；二是只能在父子进程之间使用；

② 流管道：去除第一个限制，支持双向传输；

③ 命名管道：去除第二个限制，可以在不相关进程之间进行通信。

##### 2）、信号量

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其它进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

##### 3）、消息队列

消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

##### 4）、信号

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

##### 5）、共享内存

共享内存就是映射一段能被其它进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其它进程间通信方式运行效率低而专门设计的。它往往与其它通信机制（如信号量）配合使用，来实现进程间的同步和通信。

##### 6）、套接字

套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。

#### 14、死锁

死锁定义：一个进程集合中的每个进程都在等待此进程集合中其他进程所占用的资源或能引发的事件而进入永久僵持的局面称为死锁。

##### 1）、死锁的条件

- 互斥
- 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不可抢占
- 环路等待

##### 2）、死锁处理

- 忽略该问题。一般称为鸵鸟算法，即躲起来视而不见。
- 检测死锁并恢复。让死锁发生，检测它们是否发生，一旦发生死锁，就采取行动解决问题。
- 仔细对资源进行分配，动态地避免死锁。也称为死锁避免。
- 通过破坏引起死锁的四个必要条件，防止死锁的发生。也称为死锁预防。
  - 层次分配 ：给系统的所有资源分层，一个进程得到某层的资源后只能再申请较高一层的资源；若要申请本层的其他资源，必须先释放已申请的本层资源
  - 按序分配 ：将所有资源按顺序编号，进程申请资源的顺序必须按照资源的编号进行。如某一进程已得到了Ri资源，则其不可再申请Rj资源(j<i)。

##### 3）、死锁检测和恢复

采用这种办法的时候，系统并没有试图阻止死锁的发生，而是允许死锁发生，检测到死锁后，采取措施进行恢复。

检测：我们知道，死锁的一个必要条件是存在两个及以上进程组成的环路。**通过检测有向图环路，是一种检测死锁存在的方法。**

当每种类型存在多个资源时，检测可能会复杂许多。

恢复的方法：

- **利用抢占恢复**：死锁发生的必要条件，其中一个就是不可抢占。如果允许抢占，那么就可以破坏死锁条件。
- **利用回滚**：周期性对进程进行检查点检查，一旦发现了死锁，就回滚到一个较早的检查点上。
- **通过杀死进程**：这个方法是最显而易见的。杀死一个进程可以释放它占有的资源，如果仍然不行那么久继续杀死其他进程直到打破死锁。

##### 4）、死锁避免

- 资源轨迹图：如果直到了进程在各个阶段需要哪些资源，那么可以在图中进程标注。两个进程的交叠区域就是一个会造成死锁的区域。进程在图中只能向右或者向上前进，一旦进入了危险区，那么就可能发生死锁。为了避免死锁，应当在合适的时间阻塞某个进程，使得运行避开这个区域。

##### 5）、死锁预防

死锁避免可以认为是在程序执行中动态地避免死锁发生，而死锁预防可以说是静态的方式，杜绝死锁发生的可能性。

**只要能破坏死锁发生的四个必要条件之一，那么死锁就不会发生。**

1、破坏互斥条件

尽量使得资源不被某个进程独占。比如打印机的假脱机打印，就是尽量避免一个进程独占打印机，而是把要打印的文件存入一个假脱机目录，然后通过一个守护进程管理打印机进行打印。

2、破坏占有和等待条件

禁止已经持有资源的进程再等待其他资源。

一种方式是，在进程开始执行前请求所需的全部资源，如果不能满足，那么就不分配资源，进行等待。这种方式的问题在于，类似银行家算法，事先不知道需要多少资源，而且资源利用率不高。

另一种方式就是，当一个进程请求资源时，先暂时释放其当前所占用的所有资源，然后再尝试一次获取所需的全部资源。

3、破坏不可抢占条件

这个比较好理解，允许资源抢占即可。当然，有的时候资源应当是不可抢占的。

4、破坏环路等待条件

一种方法是对资源进行编号，进程在任何时候都可以请求资源，但是所有的请求必须按照资源编号的顺序（升序）提出。

##### 6）、其他问题

1、两阶段加锁

这是针对数据库的一种方法，第一阶段对所有需要更新的记录进行加锁，一旦某个记录已经被加锁，就释放之前的锁，从头进行重试。只有当第一阶段所有获取锁的行为都成功，才进行第二阶段的更新，否则放弃所有的锁。

2、通信死锁

这种情况其实是很常见的。当一个进程A向B发送信息后挂起，需要B进程的回复唤醒时，如果请求信息丢失，A就会被阻塞以等待回复，B会阻塞等待一个向其发送命令的请求，因而发生死锁。

通信死锁不涉及资源，不能通过合理调度资源来避免。一般通信协议会解决这种问题，包括超时重传等技术。

3、**活锁**

轮询（忙等待）的方式，在有时是有效的，因为挂起进程等待的开销很大。考虑如下程序：

![程序示意图]({{site.baseurl}}/assets/img/程序示意图.png)

enter_region()通过轮询获取资源，假设A获得了资源1，B获得了资源2，那么两个进程都不会阻塞，而是不停地进行轮询以获取资源。两个进程总是运行完系统分配的时间片，没有阻塞但是不会取得进展。

4、**饥饿**

饥饿的概念，其实与死锁和活锁差别比较大。考虑进程调度，基于优先级的调度中，如果总是有高优先级的进程就绪，那么一个低优先级的进程可能长时间无法上CPU运行。这就是饥饿现象，可以考虑通过动态优先级机制，可以动态提高长时间得不到运行的进程的优先级，从而使它可以运行。

## 四、文件

> 参考资源：https://blog.csdn.net/xiaokang123456kao/article/details/74171875

#### 1、概述

操作系统对系统的软件资源（不论是应用软件和系统软件）的管理都以文件方式进行，承担这部分功能的操作系统称为文件系统。

##### 1）、文件

- **计算机系统对系统中软件资源：无论是程序或数据、系统软件或应用软件都以文件方式来管理**。文件是存贮在某种介质上的（如磁盘、磁带等）并具有文件名的一组有序信息的集合。
- MS-DOS中文件名由三部分组成，格式如下：[<盘符>] <文件名> [.扩展名]。格式 [ ] 中是可以省略，盘符为存放文件的磁盘驱动器号，如用A:和C:分别 表示软盘和硬盘驱动器；文件名由1∽8个字符组成。扩展名为由“.”开始的1-3个字符组成，如.EXE表示可执行的浮动代码文件，.TXT表示ASCⅡ码文本文件，.LIB表示库文件，.BAT表示批处理文件等。 
- UNIX 文件系统将文件分成普通文件、目录文件、设备文件（特殊文件）和符号连接文件(Symbolic link)等几类，UNIX把所有I/O设备作为特殊文件，对I/O设备操作模仿为对普通文件的存取，这样将文件与设备的I/O尽可能统一起来。
- **数据项是描述一个对象的某些属性的字符集**，它是数据的基本单位，一个数据项有一个值。**记录是一组相关数据项的集合**，用于描述一个对象某方面的属性。 文件是具有文件名的一组相关记录的集合。数据库是相关数据的集合。

##### 2）、文件系统

文件系统是操作系统中以文件方式管理计算机软件资源的软件和被管理的文件和数据结构（如目录和索引表等）的集合。 **从系统角度来看，文件系统是对文件存储器的存储空间进行组织、分配和回收，负责文件的存储、检索、共享和保护。** **从用户角度来看，文件系统主要是实现“按名存取”，文件系统的用户只要知道所需文件的文件名，就可存取文件中的信息，而无需知道这些文件究竟存放在什么地方。** 

- **FAT文件系统（MS-DOS文件系统、msdos）** ：它是MS-DOS操作系统使用的文件系统，它也能由Windows98/NT、linux、SCO UNIX等操作系统访问。文件地址以FAT表结构存放，文件目录32B，文件名为8个基本名加上一个“.”和3个字符扩展名。
- **扩展文件表系统（vfat）** ：它是Windows98使用的扩展的DOS文件系统，它在MS-DOS文件系统基础上增加了对长文件名（最多到256B）支持。 
- **NTFS（NT文件系统）**：它是Windows NT操作系统使用的文件系统，它具有很强的安全特性和文件系统恢复功能，可以处理巨大的存储媒体，支持多种文件系统。 
- **ext2（二级扩展文件系统）**：它是Linux操作系统使用的高性能磁盘文件系统，它是对Minux操作系统中使用的文件系统扩展（ext）的扩展。它支持256字符的文件名，最大可支持到4TB的文件系统大小。
- HPFS（高性能文件系统、hpfs）：它是OS/2操作系统使用的文件系统。  
- S51K/S52K（sysv）：它是AT&T UNIX S V 操作系统使用的1KB/2KB文件系统。
- CD-ROM文件系统(iso9660) ：它是符合ISO9660标准的支持CD-ROM的文件系统，它有High sierra CD-ROM和Rock Ridge CD-ROM二种类型。 
- UDF通用磁盘格式文件系统 ：UDF(Universal Disk Format)文件系统是依据光学储存技术协会（Optical Storage Technology Association, OSTA）的通用磁盘格式文件系统规格1.02版所制定的。它提供了对 UDF格式媒体的只读访问（例如DVD光盘）。Windows98提供对UDF文件系统支持。

现代操作系统（如Windows 2000/XP、Linux、UNIX等）提供了对多种文件系统的支持。 

- Windows 2000/XP ：Windows 2000/XP支持FAT文件系统、NTFS、HPFS、CD-ROM文件系统等多种文件系统。 Windows 2000执行体内I/O系统分成I/O管理程序、文件系统驱动程序和盘驱动程序三层，不同的文件系统采用不同的文件系统驱动程序，系统用动态连接库对这些文件系统进行装入和卸出并适宜于将来的扩展。 
- Linux ：Linux支持ext、ext2、msdos、vfat、iso9660、hpfs等多种文件系统。Linux采用虚拟文件系统VFS支持许多不同类型的文件系统，VFS是物理系统与服务之间的一个接口层，它屏蔽各类文件系统的差异，给用户和程序提供一个统一的接口。使用命令mkfs创建各类文件系统。



## 五、其他

#### 1、通道

**通道是独立于CPU的、专门负责数据共享以及传输工作的处理单元。**

1. 通道是计算机系统中传送信息和数据的装置。主要有主存储器读写通道和输入、输出通道。**能接收中央处理机的命令，独立执行通道程序，协助中央处理机控制与管理外部设备。一个独立于CPU的专门I/O控制的处理机，控制设备与内存直接进行数据交换。它有自己的通道命令，可由CPU执行相应指令来启动通道，并在操作结束时向CPU发出中断信号。**通道指令的格式一般由：操作码，记数段，内存地址段，结束标志组成。一个系统中可设立三种类型的通道：字节多路通道、数组多路通道、选择通道.
2. 通道的出现则进一步提高了CPU的效率．这是因为通道是一个特殊功能的处理器．它有自己的指令和程序专门负责数据输入输出的传输控制．**而CPU将“传输控制”的功能下放给通道后只负责“数据处理”功能**。
3. 单处理机计算机：在计算机体系结构中，处理机就是CPU，单处理机计算机系统中某个时刻只有一个程序在使用CPU运行，通过进程调度可以实现宏观上的多程序并行的效果，但微观上仍然是串行的。具有多个CPU的计算机系统中，某一时刻每个CPU中都可以有一个程序在运行，可以实现真正意义上的并行。

#### 2、存储空间的基本分配单位

根据块来划分，然后分成页、段，而且一般页的大小等于块的大小，段页虚拟的，块是真实储存信息的……存储空间的基本分配单位都是磁盘块而非字节。

#### 3、多通道处理系统设计

单道批处理最大的缺点是系统的资源得不到充分的利用，内存中只有一道程序，每逢改程序在运行中发出I/O请求的时候，CPU便处于等待状态，必须在I/O完成后才继续运行。

为了**进一步提高资源的利用率和系统的吞吐量，引入了多道程序设计技术**。将作业放在外存上形成一个队列A，B，C,D......，可以在A发送I/O请求的时候，执行B，同时B发送I/O的时候执行C。

#### 4、原语

原语是由若干个机器指令构成的完成某种特定功能的一段程序，具有不可分割性，即原语的执行必须是连续的。原语在执行过程中不允许被中断，不同层次之间对话的语言称为原语，即不同层之间通过原语来实现信息交换。

#### 5、操作系统分类

- 批处理是指用户将一批作业提交给操作系统后就不再干预，由操作系统控制它们自动运行。

- 分时操作系统是使一台计算机采用时间片轮转的方式同时为几个、几十个甚至几百个用户服务的一种操作系统。由于时间间隔很短，每个用户的感觉就像他独占计算机一样。

- 实时操作系统(RTOS)是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统做出快速响应，并控制所有实时任务协调一致运行的操作系统。

- 网络操作系统，是一种能代替操作系统的软件程序，是网络的心脏和灵魂，是向网络计算机提供服务的特殊的操作系统。

- 批处理（多道）系统：系统效率和吞吐量；

  分时系统：交互性和响应时间；

  实时系统：实时性和可靠性；

#### 6、文件删除

**删除文件不需要删除文件所在的目录**，而文件的关联目录项和文件控制块需要随着文件一同删除，同时释放文件的关联缓冲区。

#### 7、虚拟储存器计算方法

虚拟存储器最大实际容量= min(计算机地址，内存+辅存)。计算机地址= 2^ (段号)* 2^(段内地址)

#### 8、位示图法管理外存空间

某文件系统采用位示图法管理外存储空间，每个磁盘块4KB，已知一块磁盘容量为40GB，则表
示该磁盘所需的位示图需要占用？的内存空间

解：位示图法只有1位（bit）用来表示该磁盘块是否分配。所占用的内存空间=40GB/4KB/8=(40 * 1024 * 1024)KB/4KB/8=(10 * 1024 * 1024)/8=(10 * 1024/8)KB=1280KB

#### 9、访问扇区的时间计算

若磁盘转速是7200转/分，平均寻道时间是8ms，每个磁道包含1000个扇区，则访问一个扇区的平均存取时间为？

解：存取时间 = 寻道时间 + 延迟时间 + 传输时间。存取一个扇区的平均延迟时间为旋转半周的时间，即为 (60/7200)/2=4.17ms ，传输时间为 (60/7200)/1000=0.01ms ，因此访问一个扇区的平均存取时间为 4.17+0.01+8=12.18ms ，保留一位小数则为 12.2ms 